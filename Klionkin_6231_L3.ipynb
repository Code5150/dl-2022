{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Лабораторная работа 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) Полносвязная нейронная сеть ( Fully-Connected Neural Network)\n",
    "\n",
    "2) Нормализация по мини-батчам (Batch normalization)\n",
    "\n",
    "3) Dropout\n",
    "\n",
    "4) Сверточные нейронные сети (Convolutional Networks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Вариант 4: Сверточные нейронные сети (Convolutional Networks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Лабораторные работы можно выполнять с использованием сервиса Google Colaboratory (https://medium.com/deep-learning-turkey/google-colab-free-gpu-tutorial-e113627b9f5d) или на локальном компьютере. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Полносвязная нейронная сеть"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В данной лабораторной работе необходимо будет реализовать полносвязную нейронную сеть, используя модульный подход. Для каждого  слоя реализации прямого и обратного проходов алгоритма обратного распространения ошибки будут иметь следующий вид:\n",
    "\n",
    "```python\n",
    "def layer_forward(x, w):\n",
    "  \"\"\" Receive inputs x and weights w \"\"\"\n",
    "  # Do some computations ...\n",
    "  z = # ... some intermediate value\n",
    "  # Do some more computations ...\n",
    "  out = # the output\n",
    "   \n",
    "  cache = (x, w, z, out) # Values we need to compute gradients\n",
    "   \n",
    "  return out, cache\n",
    "```\n",
    "\n",
    "\n",
    "\n",
    "```python\n",
    "def layer_backward(dout, cache):\n",
    "  \"\"\"\n",
    "  Receive dout (derivative of loss with respect to outputs) and cache,\n",
    "  and compute derivative with respect to inputs.\n",
    "  \"\"\"\n",
    "  # Unpack cache values\n",
    "  x, w, z, out = cache\n",
    "  \n",
    "  # Use values in cache to compute derivatives\n",
    "  dx = # Derivative of loss with respect to x\n",
    "  dw = # Derivative of loss with respect to w\n",
    "  \n",
    "  return dx, dw\n",
    "```\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[WinError 2] Не удается найти указанный файл: './scripts'\n",
      "C:\\Users\\klionkinvs\\Documents\\NN_DL\\dl-2022\\scripts\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UsageError: Line magic function `%python` not found (But cell magic `%%python` exists, did you mean that instead?).\n"
     ]
    }
   ],
   "source": [
    "%cd ./scripts\n",
    "%python setup.py build_ext --inplace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import time\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scripts.classifiers.fc_net import *\n",
    "\n",
    "from scripts.gradient_check import eval_numerical_gradient, eval_numerical_gradient_array\n",
    "from scripts.solver import Solver\n",
    "from scripts.classifiers.cnn import *\n",
    "from scripts.layers import *\n",
    "from scripts.fast_layers import *\n",
    "\n",
    "\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = (10.0, 8.0)  \n",
    "plt.rcParams['image.interpolation'] = 'nearest'\n",
    "plt.rcParams['image.cmap'] = 'gray'\n",
    "\n",
    "# for auto-reloading external modules\n",
    "# see http://stackoverflow.com/questions/1907993/autoreload-of-modules-in-ipython\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "def rel_error(x, y):\n",
    "  \"\"\" returns relative error \"\"\"\n",
    "  return np.max(np.abs(x - y) / (np.maximum(1e-8, np.abs(x) + np.abs(y))))\n",
    "def print_mean_std(x,axis=0):\n",
    "    print('  means: ', x.mean(axis=axis))\n",
    "    print('  stds:  ', x.std(axis=axis))\n",
    "    print() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Загрузите данные из предыдущей лабораторной работы. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data shape:  (1293, 1, 8, 8)\n",
      "Training labels shape:  (1293,)\n",
      "Validation data shape:  (144, 1, 8, 8)\n",
      "Validation labels shape:  (144,)\n",
      "Test data shape:  (360, 1, 8, 8)\n",
      "Test labels shape:  (360,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_digits\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X, y = load_digits(return_X_y = True)\n",
    "X = X.reshape(X.shape[0], 1, np.sqrt(X.shape[1]).astype(np.int32), np.sqrt(X.shape[1]).astype(np.int32))\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = int(time()))\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size = 0.1, random_state = int(time()))\n",
    "print('Training data shape: ', X_train.shape)\n",
    "print('Training labels shape: ', y_train.shape)\n",
    "print('Validation data shape: ', X_val.shape)\n",
    "print('Validation labels shape: ', y_val.shape)\n",
    "print('Test data shape: ', X_test.shape)\n",
    "print('Test labels shape: ', y_test.shape)\n",
    "data = {\n",
    "    'X_train': X_train,\n",
    "    'X_test': X_test,\n",
    "    'X_val': X_val,\n",
    "    'y_train': y_train,\n",
    "    'y_test': y_test,\n",
    "    'y_val': y_val,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для полносвязного слоя реализуйте прямой проход (метод affine_forward в scripts/layers.py). Протестируйте свою реализацию. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_inputs = 2\n",
    "input_shape = (4, 5, 6)\n",
    "output_dim = 3\n",
    "\n",
    "input_size = num_inputs * np.prod(input_shape)\n",
    "weight_size = output_dim * np.prod(input_shape)\n",
    "\n",
    "x = np.linspace(-0.1, 0.5, num=input_size).reshape(num_inputs, *input_shape)\n",
    "w = np.linspace(-0.2, 0.3, num=weight_size).reshape(np.prod(input_shape), output_dim)\n",
    "b = np.linspace(-0.3, 0.1, num=output_dim)\n",
    "\n",
    "out, _ = affine_forward(x, w, b)\n",
    "correct_out = np.array([[ 1.49834967,  1.70660132,  1.91485297],\n",
    "                        [ 3.25553199,  3.5141327,   3.77273342]])\n",
    "\n",
    "\n",
    "print('Testing affine_forward function:')\n",
    "print('difference: ', rel_error(out, correct_out))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для полносвязного слоя реализуйте обратный проход (метод affine_backward в scripts/layers.py). Протестируйте свою реализацию. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(231)\n",
    "x = np.random.randn(10, 2, 3)\n",
    "w = np.random.randn(6, 5)\n",
    "b = np.random.randn(5)\n",
    "dout = np.random.randn(10, 5)\n",
    "\n",
    "dx_num = eval_numerical_gradient_array(lambda x: affine_forward(x, w, b)[0], x, dout)\n",
    "dw_num = eval_numerical_gradient_array(lambda w: affine_forward(x, w, b)[0], w, dout)\n",
    "db_num = eval_numerical_gradient_array(lambda b: affine_forward(x, w, b)[0], b, dout)\n",
    "\n",
    "_, cache = affine_forward(x, w, b)\n",
    "dx, dw, db = affine_backward(dout, cache)\n",
    "\n",
    "print('Testing affine_backward function:')\n",
    "print('dx error: ', rel_error(dx_num, dx))\n",
    "print('dw error: ', rel_error(dw_num, dw))\n",
    "print('db error: ', rel_error(db_num, db))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Реализуйте прямой проход для слоя активации ReLU (relu_forward) и протестируйте его."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.linspace(-0.5, 0.5, num=12).reshape(3, 4)\n",
    "\n",
    "out, _ = relu_forward(x)\n",
    "correct_out = np.array([[ 0.,          0.,          0.,          0.,        ],\n",
    "                        [ 0.,          0.,          0.04545455,  0.13636364,],\n",
    "                        [ 0.22727273,  0.31818182,  0.40909091,  0.5,       ]])\n",
    "\n",
    "# Compare your output with ours. The error should be on the order of e-8\n",
    "print('Testing relu_forward function:')\n",
    "print('difference: ', rel_error(out, correct_out))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Реализуйте обратный проход для слоя активации ReLU (relu_backward ) и протестируйте его."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(231)\n",
    "x = np.random.randn(10, 10)\n",
    "dout = np.random.randn(*x.shape)\n",
    "\n",
    "dx_num = eval_numerical_gradient_array(lambda x: relu_forward(x)[0], x, dout)\n",
    "\n",
    "_, cache = relu_forward(x)\n",
    "dx = relu_backward(dout, cache)\n",
    "\n",
    "# The error should be on the order of e-12\n",
    "print('Testing relu_backward function:')\n",
    "print('dx error: ', rel_error(dx_num, dx))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В скрипте /layer_utils.py приведены реализации прямого и обратного проходов для часто используемых комбинаций слоев. Например, за полносвязным слоем часто следует слой активации. Ознакомьтесь с функциями affine_relu_forward и affine_relu_backward, запустите код ниже и убедитесь, что ошибка порядка e-10 или ниже. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scripts.layer_utils import affine_relu_forward, affine_relu_backward\n",
    "np.random.seed(231)\n",
    "x = np.random.randn(2, 3, 4)\n",
    "w = np.random.randn(12, 10)\n",
    "b = np.random.randn(10)\n",
    "dout = np.random.randn(2, 10)\n",
    "\n",
    "out, cache = affine_relu_forward(x, w, b)\n",
    "dx, dw, db = affine_relu_backward(dout, cache)\n",
    "\n",
    "dx_num = eval_numerical_gradient_array(lambda x: affine_relu_forward(x, w, b)[0], x, dout)\n",
    "dw_num = eval_numerical_gradient_array(lambda w: affine_relu_forward(x, w, b)[0], w, dout)\n",
    "db_num = eval_numerical_gradient_array(lambda b: affine_relu_forward(x, w, b)[0], b, dout)\n",
    "\n",
    "# Relative error should be around e-10 or less\n",
    "print('Testing affine_relu_forward and affine_relu_backward:')\n",
    "print('dx error: ', rel_error(dx_num, dx))\n",
    "print('dw error: ', rel_error(dw_num, dw))\n",
    "print('db error: ', rel_error(db_num, db))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Реализуйте двухслойную полносвязную сеть - класс TwoLayerNet в scripts/classifiers/fc_net.py . Проверьте свою реализацию, запустив код ниже. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(231)\n",
    "N, D, H, C = 3, 5, 50, 7\n",
    "X = np.random.randn(N, D)\n",
    "y = np.random.randint(C, size=N)\n",
    "\n",
    "std = 1e-3\n",
    "model = TwoLayerNet(input_dim=D, hidden_dim=H, num_classes=C, weight_scale=std)\n",
    "\n",
    "print('Testing initialization ... ')\n",
    "W1_std = abs(model.params['W1'].std() - std)\n",
    "b1 = model.params['b1']\n",
    "W2_std = abs(model.params['W2'].std() - std)\n",
    "b2 = model.params['b2']\n",
    "assert W1_std < std / 10, 'First layer weights do not seem right'\n",
    "assert np.all(b1 == 0), 'First layer biases do not seem right'\n",
    "assert W2_std < std / 10, 'Second layer weights do not seem right'\n",
    "assert np.all(b2 == 0), 'Second layer biases do not seem right'\n",
    "\n",
    "print('Testing test-time forward pass ... ')\n",
    "model.params['W1'] = np.linspace(-0.7, 0.3, num=D*H).reshape(D, H)\n",
    "model.params['b1'] = np.linspace(-0.1, 0.9, num=H)\n",
    "model.params['W2'] = np.linspace(-0.3, 0.4, num=H*C).reshape(H, C)\n",
    "model.params['b2'] = np.linspace(-0.9, 0.1, num=C)\n",
    "X = np.linspace(-5.5, 4.5, num=N*D).reshape(D, N).T\n",
    "scores = model.loss(X)\n",
    "correct_scores = np.asarray(\n",
    "  [[11.53165108,  12.2917344,   13.05181771,  13.81190102,  14.57198434, 15.33206765,  16.09215096],\n",
    "   [12.05769098,  12.74614105,  13.43459113,  14.1230412,   14.81149128, 15.49994135,  16.18839143],\n",
    "   [12.58373087,  13.20054771,  13.81736455,  14.43418138,  15.05099822, 15.66781506,  16.2846319 ]])\n",
    "scores_diff = np.abs(scores - correct_scores).sum()\n",
    "assert scores_diff < 1e-6, 'Problem with test-time forward pass'\n",
    "\n",
    "print('Testing training loss (no regularization)')\n",
    "y = np.asarray([0, 5, 1])\n",
    "loss, grads = model.loss(X, y)\n",
    "correct_loss = 3.4702243556\n",
    "assert abs(loss - correct_loss) < 1e-10, 'Problem with training-time loss'\n",
    "\n",
    "model.reg = 1.0\n",
    "loss, grads = model.loss(X, y)\n",
    "correct_loss = 26.5948426952\n",
    "assert abs(loss - correct_loss) < 1e-10, 'Problem with regularization loss'\n",
    "\n",
    "# Errors should be around e-7 or less\n",
    "for reg in [0.0, 0.7]:\n",
    "  print('Running numeric gradient check with reg = ', reg)\n",
    "  model.reg = reg\n",
    "  loss, grads = model.loss(X, y)\n",
    "\n",
    "  for name in sorted(grads):\n",
    "    f = lambda _: model.loss(X, y)[0]\n",
    "    grad_num = eval_numerical_gradient(f, model.params[name], verbose=False)\n",
    "    print('%s relative error: %.2e' % (name, rel_error(grad_num, grads[name])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ознакомьтесь с API для обучения и тестирования моделей в scripts/solver.py . Используйте экземпляр класса Solver для обучения двухслойной полносвязной сети. Необходимо достичь минимум 50% верно классифицированных объектов на валидационном наборе. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = TwoLayerNet()\n",
    "solver = None\n",
    "\n",
    "##############################################################################\n",
    "# TODO: Use a Solver instance to train a TwoLayerNet that achieves at least  #\n",
    "# 50% accuracy on the validation set.                                        #\n",
    "##############################################################################\n",
    "# *****START OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n",
    "\n",
    "pass\n",
    "\n",
    "# *****END OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n",
    "##############################################################################\n",
    "#                             END OF YOUR CODE                               #\n",
    "##############################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.subplot(2, 1, 1)\n",
    "plt.title('Training loss')\n",
    "plt.plot(solver.loss_history, 'o')\n",
    "plt.xlabel('Iteration')\n",
    "\n",
    "plt.subplot(2, 1, 2)\n",
    "plt.title('Accuracy')\n",
    "plt.plot(solver.train_acc_history, '-o', label='train')\n",
    "plt.plot(solver.val_acc_history, '-o', label='val')\n",
    "plt.plot([0.5] * len(solver.val_acc_history), 'k--')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(loc='lower right')\n",
    "plt.gcf().set_size_inches(15, 12)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь реализуйте полносвязную сеть с произвольным числом скрытых слоев. Ознакомьтесь с классом FullyConnectedNet в scripts/classifiers/fc_net.py . Реализуйте инициализацию, прямой и обратный проходы."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(231)\n",
    "N, D, H1, H2, C = 2, 15, 20, 30, 10\n",
    "X = np.random.randn(N, D)\n",
    "y = np.random.randint(C, size=(N,))\n",
    "\n",
    "for reg in [0, 3.14]:\n",
    "  print('Running check with reg = ', reg)\n",
    "  model = FullyConnectedNet([H1, H2], input_dim=D, num_classes=C,\n",
    "                            reg=reg, weight_scale=5e-2, dtype=np.float64)\n",
    "\n",
    "  loss, grads = model.loss(X, y)\n",
    "  print('Initial loss: ', loss)\n",
    "  \n",
    "  # Most of the errors should be on the order of e-7 or smaller.   \n",
    "  # NOTE: It is fine however to see an error for W2 on the order of e-5\n",
    "  # for the check when reg = 0.0\n",
    "  for name in sorted(grads):\n",
    "    f = lambda _: model.loss(X, y)[0]\n",
    "    grad_num = eval_numerical_gradient(f, model.params[name], verbose=False, h=1e-5)\n",
    "    print('%s relative error: %.2e' % (name, rel_error(grad_num, grads[name])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Попробуйте добиться эффекта переобучения на небольшом наборе изображений (например, 50). Используйте трехслойную сеть со 100 нейронами на каждом скрытом слое. Попробуйте переобучить сеть, достигнув 100 % accuracy за 20 эпох. Для этого поэкспериментируйте с параметрами weight_scale и learning_rate. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Use a three-layer Net to overfit 50 training examples by \n",
    "# tweaking just the learning rate and initialization scale.\n",
    "\n",
    "num_train = 50\n",
    "small_data = {\n",
    "  'X_train': data['X_train'][:num_train],\n",
    "  'y_train': data['y_train'][:num_train],\n",
    "  'X_val': data['X_val'],\n",
    "  'y_val': data['y_val'],\n",
    "}\n",
    "\n",
    "weight_scale = 1e-2   # Experiment with this!\n",
    "learning_rate = 1e-4  # Experiment with this!\n",
    "model = FullyConnectedNet([100, 100],\n",
    "              weight_scale=weight_scale, dtype=np.float64)\n",
    "solver = Solver(model, small_data,\n",
    "                print_every=10, num_epochs=20, batch_size=25,\n",
    "                update_rule='sgd',\n",
    "                optim_config={\n",
    "                  'learning_rate': learning_rate,\n",
    "                }\n",
    "         )\n",
    "solver.train()\n",
    "\n",
    "plt.plot(solver.loss_history, 'o')\n",
    "plt.title('Training loss history')\n",
    "plt.xlabel('Iteration')\n",
    "plt.ylabel('Training loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Повторите эксперимент, описанный выше, для пятислойной сети."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Use a five-layer Net to overfit 50 training examples by \n",
    "# tweaking just the learning rate and initialization scale.\n",
    "\n",
    "num_train = 50\n",
    "small_data = {\n",
    "  'X_train': data['X_train'][:num_train],\n",
    "  'y_train': data['y_train'][:num_train],\n",
    "  'X_val': data['X_val'],\n",
    "  'y_val': data['y_val'],\n",
    "}\n",
    "\n",
    "learning_rate = 2e-3  # Experiment with this!\n",
    "weight_scale = 1e-5   # Experiment with this!\n",
    "model = FullyConnectedNet([100, 100, 100, 100],\n",
    "                weight_scale=weight_scale, dtype=np.float64)\n",
    "solver = Solver(model, small_data,\n",
    "                print_every=10, num_epochs=20, batch_size=25,\n",
    "                update_rule='sgd',\n",
    "                optim_config={\n",
    "                  'learning_rate': learning_rate,\n",
    "                }\n",
    "         )\n",
    "solver.train()\n",
    "\n",
    "plt.plot(solver.loss_history, 'o')\n",
    "plt.title('Training loss history')\n",
    "plt.xlabel('Iteration')\n",
    "plt.ylabel('Training loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сделайте выводы по проведенному эксперименту. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ранее обновление весов проходило по правилу SGD. Теперь попробуйте реализовать стохастический градиентный спуск с импульсом (SGD+momentum). http://cs231n.github.io/neural-networks-3/#sgd Реализуйте sgd_momentum в scripts/optim.py  и запустите проверку. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scripts.optim import sgd_momentum\n",
    "\n",
    "N, D = 4, 5\n",
    "w = np.linspace(-0.4, 0.6, num=N*D).reshape(N, D)\n",
    "dw = np.linspace(-0.6, 0.4, num=N*D).reshape(N, D)\n",
    "v = np.linspace(0.6, 0.9, num=N*D).reshape(N, D)\n",
    "\n",
    "config = {'learning_rate': 1e-3, 'velocity': v}\n",
    "next_w, _ = sgd_momentum(w, dw, config=config)\n",
    "\n",
    "expected_next_w = np.asarray([\n",
    "  [ 0.1406,      0.20738947,  0.27417895,  0.34096842,  0.40775789],\n",
    "  [ 0.47454737,  0.54133684,  0.60812632,  0.67491579,  0.74170526],\n",
    "  [ 0.80849474,  0.87528421,  0.94207368,  1.00886316,  1.07565263],\n",
    "  [ 1.14244211,  1.20923158,  1.27602105,  1.34281053,  1.4096    ]])\n",
    "expected_velocity = np.asarray([\n",
    "  [ 0.5406,      0.55475789,  0.56891579, 0.58307368,  0.59723158],\n",
    "  [ 0.61138947,  0.62554737,  0.63970526,  0.65386316,  0.66802105],\n",
    "  [ 0.68217895,  0.69633684,  0.71049474,  0.72465263,  0.73881053],\n",
    "  [ 0.75296842,  0.76712632,  0.78128421,  0.79544211,  0.8096    ]])\n",
    "\n",
    "# Should see relative errors around e-8 or less\n",
    "print('next_w error: ', rel_error(next_w, expected_next_w))\n",
    "print('velocity error: ', rel_error(expected_velocity, config['velocity']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сравните результаты обучения шестислойной сети, обученной классическим градиентным спуском и адаптивным алгоритмом с импульсом. Какой алгоритм сходится быстрее."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_train = 4000\n",
    "small_data = {\n",
    "  'X_train': data['X_train'][:num_train],\n",
    "  'y_train': data['y_train'][:num_train],\n",
    "  'X_val': data['X_val'],\n",
    "  'y_val': data['y_val'],\n",
    "}\n",
    "\n",
    "solvers = {}\n",
    "\n",
    "for update_rule in ['sgd', 'sgd_momentum']:\n",
    "  print('running with ', update_rule)\n",
    "  model = FullyConnectedNet([100, 100, 100, 100, 100], weight_scale=5e-2)\n",
    "\n",
    "  solver = Solver(model, small_data,\n",
    "                  num_epochs=5, batch_size=100,\n",
    "                  update_rule=update_rule,\n",
    "                  optim_config={\n",
    "                    'learning_rate': 5e-3,\n",
    "                  },\n",
    "                  verbose=True)\n",
    "  solvers[update_rule] = solver\n",
    "  solver.train()\n",
    "  print()\n",
    "\n",
    "plt.subplot(3, 1, 1)\n",
    "plt.title('Training loss')\n",
    "plt.xlabel('Iteration')\n",
    "\n",
    "plt.subplot(3, 1, 2)\n",
    "plt.title('Training accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "\n",
    "plt.subplot(3, 1, 3)\n",
    "plt.title('Validation accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "\n",
    "for update_rule, solver in solvers.items():\n",
    "  plt.subplot(3, 1, 1)\n",
    "  plt.plot(solver.loss_history, 'o', label=\"loss_%s\" % update_rule)\n",
    "  \n",
    "  plt.subplot(3, 1, 2)\n",
    "  plt.plot(solver.train_acc_history, '-o', label=\"train_acc_%s\" % update_rule)\n",
    "\n",
    "  plt.subplot(3, 1, 3)\n",
    "  plt.plot(solver.val_acc_history, '-o', label=\"val_acc_%s\" % update_rule)\n",
    "  \n",
    "for i in [1, 2, 3]:\n",
    "  plt.subplot(3, 1, i)\n",
    "  plt.legend(loc='upper center', ncol=4)\n",
    "plt.gcf().set_size_inches(15, 15)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Реализуйте алгоритмы RMSProp [1] and Adam [2] с коррекцией смещения  - методы rmsprop и adam . \n",
    "\n",
    "\n",
    "[1] Tijmen Tieleman and Geoffrey Hinton. \"Lecture 6.5-rmsprop: Divide the gradient by a running average of its recent magnitude.\" COURSERA: Neural Networks for Machine Learning 4 (2012).\n",
    "\n",
    "[2] Diederik Kingma and Jimmy Ba, \"Adam: A Method for Stochastic Optimization\", ICLR 2015."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test RMSProp implementation\n",
    "from scripts.optim import rmsprop\n",
    "\n",
    "N, D = 4, 5\n",
    "w = np.linspace(-0.4, 0.6, num=N*D).reshape(N, D)\n",
    "dw = np.linspace(-0.6, 0.4, num=N*D).reshape(N, D)\n",
    "cache = np.linspace(0.6, 0.9, num=N*D).reshape(N, D)\n",
    "\n",
    "config = {'learning_rate': 1e-2, 'cache': cache}\n",
    "next_w, _ = rmsprop(w, dw, config=config)\n",
    "\n",
    "expected_next_w = np.asarray([\n",
    "  [-0.39223849, -0.34037513, -0.28849239, -0.23659121, -0.18467247],\n",
    "  [-0.132737,   -0.08078555, -0.02881884,  0.02316247,  0.07515774],\n",
    "  [ 0.12716641,  0.17918792,  0.23122175,  0.28326742,  0.33532447],\n",
    "  [ 0.38739248,  0.43947102,  0.49155973,  0.54365823,  0.59576619]])\n",
    "expected_cache = np.asarray([\n",
    "  [ 0.5976,      0.6126277,   0.6277108,   0.64284931,  0.65804321],\n",
    "  [ 0.67329252,  0.68859723,  0.70395734,  0.71937285,  0.73484377],\n",
    "  [ 0.75037008,  0.7659518,   0.78158892,  0.79728144,  0.81302936],\n",
    "  [ 0.82883269,  0.84469141,  0.86060554,  0.87657507,  0.8926    ]])\n",
    "\n",
    "# You should see relative errors around e-7 or less\n",
    "print('next_w error: ', rel_error(expected_next_w, next_w))\n",
    "print('cache error: ', rel_error(expected_cache, config['cache']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test Adam implementation\n",
    "from scripts.optim import adam\n",
    "\n",
    "N, D = 4, 5\n",
    "w = np.linspace(-0.4, 0.6, num=N*D).reshape(N, D)\n",
    "dw = np.linspace(-0.6, 0.4, num=N*D).reshape(N, D)\n",
    "m = np.linspace(0.6, 0.9, num=N*D).reshape(N, D)\n",
    "v = np.linspace(0.7, 0.5, num=N*D).reshape(N, D)\n",
    "\n",
    "config = {'learning_rate': 1e-2, 'm': m, 'v': v, 't': 5}\n",
    "next_w, _ = adam(w, dw, config=config)\n",
    "\n",
    "expected_next_w = np.asarray([\n",
    "  [-0.40094747, -0.34836187, -0.29577703, -0.24319299, -0.19060977],\n",
    "  [-0.1380274,  -0.08544591, -0.03286534,  0.01971428,  0.0722929],\n",
    "  [ 0.1248705,   0.17744702,  0.23002243,  0.28259667,  0.33516969],\n",
    "  [ 0.38774145,  0.44031188,  0.49288093,  0.54544852,  0.59801459]])\n",
    "expected_v = np.asarray([\n",
    "  [ 0.69966,     0.68908382,  0.67851319,  0.66794809,  0.65738853,],\n",
    "  [ 0.64683452,  0.63628604,  0.6257431,   0.61520571,  0.60467385,],\n",
    "  [ 0.59414753,  0.58362676,  0.57311152,  0.56260183,  0.55209767,],\n",
    "  [ 0.54159906,  0.53110598,  0.52061845,  0.51013645,  0.49966,   ]])\n",
    "expected_m = np.asarray([\n",
    "  [ 0.48,        0.49947368,  0.51894737,  0.53842105,  0.55789474],\n",
    "  [ 0.57736842,  0.59684211,  0.61631579,  0.63578947,  0.65526316],\n",
    "  [ 0.67473684,  0.69421053,  0.71368421,  0.73315789,  0.75263158],\n",
    "  [ 0.77210526,  0.79157895,  0.81105263,  0.83052632,  0.85      ]])\n",
    "\n",
    "# You should see relative errors around e-7 or less\n",
    "print('next_w error: ', rel_error(expected_next_w, next_w))\n",
    "print('v error: ', rel_error(expected_v, config['v']))\n",
    "print('m error: ', rel_error(expected_m, config['m']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обучите пару глубоких сетей с испольованием RMSProp и Adam алгоритмов обновления весов и сравните результаты обучения."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Получите лучшую полносвязную сеть для классификации вашего набора данных. На наборе CIFAR-10 необходимо получить accuracy не ниже 50 % на валидационном наборе."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = None\n",
    "################################################################################\n",
    "# TODO: Train the best FullyConnectedNet that you can on CIFAR-10. You might   #\n",
    "# find batch/layer normalization and dropout useful. Store your best model in  #\n",
    "# the best_model variable.                                                     #\n",
    "################################################################################\n",
    "# *****START OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n",
    "\n",
    "pass\n",
    "\n",
    "# *****END OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n",
    "################################################################################\n",
    "#                              END OF YOUR CODE                                #\n",
    "################################################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Получите оценку accuracy для валидационной и тестовой выборок. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_pred = np.argmax(best_model.loss(data['X_test']), axis=1)\n",
    "y_val_pred = np.argmax(best_model.loss(data['X_val']), axis=1)\n",
    "print('Validation set accuracy: ', (y_val_pred == data['y_val']).mean())\n",
    "print('Test set accuracy: ', (y_test_pred == data['y_test']).mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Нормализация по мини-батчам\n",
    "\n",
    "Идея нормализации по мини-батчам предложена в работе [1]\n",
    "\n",
    "[1] Sergey Ioffe and Christian Szegedy, \"Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift\", ICML 2015."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Реализуйте прямой проход для слоя батч-нормализации - функция batchnorm_forward в scripts/layers.py . Проверьте свою реализацию, запустив следующий код:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the training-time forward pass by checking means and variances\n",
    "# of features both before and after batch normalization   \n",
    "\n",
    "# Simulate the forward pass for a two-layer network\n",
    "np.random.seed(231)\n",
    "N, D1, D2, D3 = 200, 50, 60, 3\n",
    "X = np.random.randn(N, D1)\n",
    "W1 = np.random.randn(D1, D2)\n",
    "W2 = np.random.randn(D2, D3)\n",
    "a = np.maximum(0, X.dot(W1)).dot(W2)\n",
    "\n",
    "print('Before batch normalization:')\n",
    "print_mean_std(a,axis=0)\n",
    "\n",
    "gamma = np.ones((D3,))\n",
    "beta = np.zeros((D3,))\n",
    "# Means should be close to zero and stds close to one\n",
    "print('After batch normalization (gamma=1, beta=0)')\n",
    "a_norm, _ = batchnorm_forward(a, gamma, beta, {'mode': 'train'})\n",
    "print_mean_std(a_norm,axis=0)\n",
    "\n",
    "gamma = np.asarray([1.0, 2.0, 3.0])\n",
    "beta = np.asarray([11.0, 12.0, 13.0])\n",
    "# Now means should be close to beta and stds close to gamma\n",
    "print('After batch normalization (gamma=', gamma, ', beta=', beta, ')')\n",
    "a_norm, _ = batchnorm_forward(a, gamma, beta, {'mode': 'train'})\n",
    "print_mean_std(a_norm,axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the test-time forward pass by running the training-time\n",
    "# forward pass many times to warm up the running averages, and then\n",
    "# checking the means and variances of activations after a test-time\n",
    "# forward pass.\n",
    "\n",
    "np.random.seed(231)\n",
    "N, D1, D2, D3 = 200, 50, 60, 3\n",
    "W1 = np.random.randn(D1, D2)\n",
    "W2 = np.random.randn(D2, D3)\n",
    "\n",
    "bn_param = {'mode': 'train'}\n",
    "gamma = np.ones(D3)\n",
    "beta = np.zeros(D3)\n",
    "\n",
    "for t in range(50):\n",
    "  X = np.random.randn(N, D1)\n",
    "  a = np.maximum(0, X.dot(W1)).dot(W2)\n",
    "  batchnorm_forward(a, gamma, beta, bn_param)\n",
    "\n",
    "bn_param['mode'] = 'test'\n",
    "X = np.random.randn(N, D1)\n",
    "a = np.maximum(0, X.dot(W1)).dot(W2)\n",
    "a_norm, _ = batchnorm_forward(a, gamma, beta, bn_param)\n",
    "\n",
    "# Means should be close to zero and stds close to one, but will be\n",
    "# noisier than training-time forward passes.\n",
    "print('After batch normalization (test-time):')\n",
    "print_mean_std(a_norm,axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Реализуйте обратный проход в функции batchnorm_backward."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gradient check batchnorm backward pass\n",
    "np.random.seed(231)\n",
    "N, D = 4, 5\n",
    "x = 5 * np.random.randn(N, D) + 12\n",
    "gamma = np.random.randn(D)\n",
    "beta = np.random.randn(D)\n",
    "dout = np.random.randn(N, D)\n",
    "\n",
    "bn_param = {'mode': 'train'}\n",
    "fx = lambda x: batchnorm_forward(x, gamma, beta, bn_param)[0]\n",
    "fg = lambda a: batchnorm_forward(x, a, beta, bn_param)[0]\n",
    "fb = lambda b: batchnorm_forward(x, gamma, b, bn_param)[0]\n",
    "\n",
    "dx_num = eval_numerical_gradient_array(fx, x, dout)\n",
    "da_num = eval_numerical_gradient_array(fg, gamma.copy(), dout)\n",
    "db_num = eval_numerical_gradient_array(fb, beta.copy(), dout)\n",
    "\n",
    "_, cache = batchnorm_forward(x, gamma, beta, bn_param)\n",
    "dx, dgamma, dbeta = batchnorm_backward(dout, cache)\n",
    "#You should expect to see relative errors between 1e-13 and 1e-8\n",
    "print('dx error: ', rel_error(dx_num, dx))\n",
    "print('dgamma error: ', rel_error(da_num, dgamma))\n",
    "print('dbeta error: ', rel_error(db_num, dbeta))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Измените реализацию класса FullyConnectedNet, добавив батч-нормализацию. \n",
    "Если флаг normalization == \"batchnorm\", то вам необходимо вставить слой батч-нормализации перед каждым слоем активации ReLU, кроме выхода сети. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(231)\n",
    "N, D, H1, H2, C = 2, 15, 20, 30, 10\n",
    "X = np.random.randn(N, D)\n",
    "y = np.random.randint(C, size=(N,))\n",
    "\n",
    "# You should expect losses between 1e-4~1e-10 for W, \n",
    "# losses between 1e-08~1e-10 for b,\n",
    "# and losses between 1e-08~1e-09 for beta and gammas.\n",
    "for reg in [0, 3.14]:\n",
    "  print('Running check with reg = ', reg)\n",
    "  model = FullyConnectedNet([H1, H2], input_dim=D, num_classes=C,\n",
    "                            reg=reg, weight_scale=5e-2, dtype=np.float64,\n",
    "                            normalization='batchnorm')\n",
    "\n",
    "  loss, grads = model.loss(X, y)\n",
    "  print('Initial loss: ', loss)\n",
    "\n",
    "  for name in sorted(grads):\n",
    "    f = lambda _: model.loss(X, y)[0]\n",
    "    grad_num = eval_numerical_gradient(f, model.params[name], verbose=False, h=1e-5)\n",
    "    print('%s relative error: %.2e' % (name, rel_error(grad_num, grads[name])))\n",
    "  if reg == 0: print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обучите 6-ти слойную сеть на наборе из 1000 изображений с батч-нормализацией и без нее"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(231)\n",
    "# Try training a very deep net with batchnorm\n",
    "hidden_dims = [100, 100, 100, 100, 100]\n",
    "\n",
    "num_train = 1000\n",
    "small_data = {\n",
    "  'X_train': data['X_train'][:num_train],\n",
    "  'y_train': data['y_train'][:num_train],\n",
    "  'X_val': data['X_val'],\n",
    "  'y_val': data['y_val'],\n",
    "}\n",
    "\n",
    "weight_scale = 2e-2\n",
    "bn_model = FullyConnectedNet(hidden_dims, weight_scale=weight_scale, normalization='batchnorm')\n",
    "model = FullyConnectedNet(hidden_dims, weight_scale=weight_scale, normalization=None)\n",
    "\n",
    "print('Solver with batch norm:')\n",
    "bn_solver = Solver(bn_model, small_data,\n",
    "                num_epochs=10, batch_size=50,\n",
    "                update_rule='adam',\n",
    "                optim_config={\n",
    "                  'learning_rate': 1e-3,\n",
    "                },\n",
    "                verbose=True,print_every=20)\n",
    "bn_solver.train()\n",
    "\n",
    "print('\\nSolver without batch norm:')\n",
    "solver = Solver(model, small_data,\n",
    "                num_epochs=10, batch_size=50,\n",
    "                update_rule='adam',\n",
    "                optim_config={\n",
    "                  'learning_rate': 1e-3,\n",
    "                },\n",
    "                verbose=True, print_every=20)\n",
    "solver.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Визуализируйте процесс обучения для двух сетей. Увеличилась ли скорость сходимости в случае с батч-нормализацией? Сделайте выводы. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_training_history(title, label, baseline, bn_solvers, plot_fn, bl_marker='.', bn_marker='.', labels=None):\n",
    "    \"\"\"utility function for plotting training history\"\"\"\n",
    "    plt.title(title)\n",
    "    plt.xlabel(label)\n",
    "    bn_plots = [plot_fn(bn_solver) for bn_solver in bn_solvers]\n",
    "    bl_plot = plot_fn(baseline)\n",
    "    num_bn = len(bn_plots)\n",
    "    for i in range(num_bn):\n",
    "        label='with_norm'\n",
    "        if labels is not None:\n",
    "            label += str(labels[i])\n",
    "        plt.plot(bn_plots[i], bn_marker, label=label)\n",
    "    label='baseline'\n",
    "    if labels is not None:\n",
    "        label += str(labels[0])\n",
    "    plt.plot(bl_plot, bl_marker, label=label)\n",
    "    plt.legend(loc='lower center', ncol=num_bn+1) \n",
    "\n",
    "    \n",
    "plt.subplot(3, 1, 1)\n",
    "plot_training_history('Training loss','Iteration', solver, [bn_solver], \\\n",
    "                      lambda x: x.loss_history, bl_marker='o', bn_marker='o')\n",
    "plt.subplot(3, 1, 2)\n",
    "plot_training_history('Training accuracy','Epoch', solver, [bn_solver], \\\n",
    "                      lambda x: x.train_acc_history, bl_marker='-o', bn_marker='-o')\n",
    "plt.subplot(3, 1, 3)\n",
    "plot_training_history('Validation accuracy','Epoch', solver, [bn_solver], \\\n",
    "                      lambda x: x.val_acc_history, bl_marker='-o', bn_marker='-o')\n",
    "\n",
    "plt.gcf().set_size_inches(15, 15)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обучите 6-тислойную сеть с батч-нормализацией и без нее, используя разные размеры батча. Визуализируйте графики обучения. Сделайте выводы по результатам эксперимента. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_batchsize_experiments(normalization_mode):\n",
    "    np.random.seed(231)\n",
    "    # Try training a very deep net with batchnorm\n",
    "    hidden_dims = [100, 100, 100, 100, 100]\n",
    "    num_train = 1000\n",
    "    small_data = {\n",
    "      'X_train': data['X_train'][:num_train],\n",
    "      'y_train': data['y_train'][:num_train],\n",
    "      'X_val': data['X_val'],\n",
    "      'y_val': data['y_val'],\n",
    "    }\n",
    "    n_epochs=10\n",
    "    weight_scale = 2e-2\n",
    "    batch_sizes = [5,10,50]\n",
    "    lr = 10**(-3.5)\n",
    "    solver_bsize = batch_sizes[0]\n",
    "\n",
    "    print('No normalization: batch size = ',solver_bsize)\n",
    "    model = FullyConnectedNet(hidden_dims, weight_scale=weight_scale, normalization=None)\n",
    "    solver = Solver(model, small_data,\n",
    "                    num_epochs=n_epochs, batch_size=solver_bsize,\n",
    "                    update_rule='adam',\n",
    "                    optim_config={\n",
    "                      'learning_rate': lr,\n",
    "                    },\n",
    "                    verbose=False)\n",
    "    solver.train()\n",
    "    \n",
    "    bn_solvers = []\n",
    "    for i in range(len(batch_sizes)):\n",
    "        b_size=batch_sizes[i]\n",
    "        print('Normalization: batch size = ',b_size)\n",
    "        bn_model = FullyConnectedNet(hidden_dims, weight_scale=weight_scale, normalization=normalization_mode)\n",
    "        bn_solver = Solver(bn_model, small_data,\n",
    "                        num_epochs=n_epochs, batch_size=b_size,\n",
    "                        update_rule='adam',\n",
    "                        optim_config={\n",
    "                          'learning_rate': lr,\n",
    "                        },\n",
    "                        verbose=False)\n",
    "        bn_solver.train()\n",
    "        bn_solvers.append(bn_solver)\n",
    "        \n",
    "    return bn_solvers, solver, batch_sizes\n",
    "\n",
    "batch_sizes = [5,10,50]\n",
    "bn_solvers_bsize, solver_bsize, batch_sizes = run_batchsize_experiments('batchnorm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.subplot(2, 1, 1)\n",
    "plot_training_history('Training accuracy (Batch Normalization)','Epoch', solver_bsize, bn_solvers_bsize, \\\n",
    "                      lambda x: x.train_acc_history, bl_marker='-^', bn_marker='-o', labels=batch_sizes)\n",
    "plt.subplot(2, 1, 2)\n",
    "plot_training_history('Validation accuracy (Batch Normalization)','Epoch', solver_bsize, bn_solvers_bsize, \\\n",
    "                      lambda x: x.val_acc_history, bl_marker='-^', bn_marker='-o', labels=batch_sizes)\n",
    "\n",
    "plt.gcf().set_size_inches(15, 10)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dropout"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Реализуйте прямой проход для dropout-слоя в scripts/layers.py\n",
    "\n",
    "http://cs231n.github.io/neural-networks-2/#reg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(231)\n",
    "x = np.random.randn(500, 500) + 10\n",
    "\n",
    "for p in [0.25, 0.4, 0.7]:\n",
    "  out, _ = dropout_forward(x, {'mode': 'train', 'p': p})\n",
    "  out_test, _ = dropout_forward(x, {'mode': 'test', 'p': p})\n",
    "\n",
    "  print('Running tests with p = ', p)\n",
    "  print('Mean of input: ', x.mean())\n",
    "  print('Mean of train-time output: ', out.mean())\n",
    "  print('Mean of test-time output: ', out_test.mean())\n",
    "  print('Fraction of train-time output set to zero: ', (out == 0).mean())\n",
    "  print('Fraction of test-time output set to zero: ', (out_test == 0).mean())\n",
    "  print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Реализуйте обратный проход для dropout-слоя"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(231)\n",
    "x = np.random.randn(10, 10) + 10\n",
    "dout = np.random.randn(*x.shape)\n",
    "\n",
    "dropout_param = {'mode': 'train', 'p': 0.2, 'seed': 123}\n",
    "out, cache = dropout_forward(x, dropout_param)\n",
    "dx = dropout_backward(dout, cache)\n",
    "dx_num = eval_numerical_gradient_array(lambda xx: dropout_forward(xx, dropout_param)[0], x, dout)\n",
    "\n",
    "# Error should be around e-10 or less\n",
    "print('dx relative error: ', rel_error(dx, dx_num))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Добавьте в реализацию класса FullyConnectedNet поддержку dropout. Если параметр dropout != 1, то добавьте в модель dropout-слой после каждого слоя активации. Проверьте свою реализацию"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(231)\n",
    "N, D, H1, H2, C = 2, 15, 20, 30, 10\n",
    "X = np.random.randn(N, D)\n",
    "y = np.random.randint(C, size=(N,))\n",
    "\n",
    "for dropout in [1, 0.75, 0.5]:\n",
    "  print('Running check with dropout = ', dropout)\n",
    "  model = FullyConnectedNet([H1, H2], input_dim=D, num_classes=C,\n",
    "                            weight_scale=5e-2, dtype=np.float64,\n",
    "                            dropout=dropout, seed=123)\n",
    "\n",
    "  loss, grads = model.loss(X, y)\n",
    "  print('Initial loss: ', loss)\n",
    "  \n",
    "  # Relative errors should be around e-6 or less; Note that it's fine\n",
    "  # if for dropout=1 you have W2 error be on the order of e-5.\n",
    "  for name in sorted(grads):\n",
    "    f = lambda _: model.loss(X, y)[0]\n",
    "    grad_num = eval_numerical_gradient(f, model.params[name], verbose=False, h=1e-5)\n",
    "    print('%s relative error: %.2e' % (name, rel_error(grad_num, grads[name])))\n",
    "  print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обучите две двухслойные сети с dropout-слоем (вероятность отсева 0,25) и без на наборе из 500 изображений. Визуализируйте графики обучения. Сделайте выводы по результатам эксперимента"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train two identical nets, one with dropout and one without\n",
    "np.random.seed(231)\n",
    "num_train = 500\n",
    "small_data = {\n",
    "  'X_train': data['X_train'][:num_train],\n",
    "  'y_train': data['y_train'][:num_train],\n",
    "  'X_val': data['X_val'],\n",
    "  'y_val': data['y_val'],\n",
    "}\n",
    "\n",
    "solvers = {}\n",
    "dropout_choices = [1, 0.25]\n",
    "for dropout in dropout_choices:\n",
    "  model = FullyConnectedNet([500], dropout=dropout)\n",
    "  print(dropout)\n",
    "\n",
    "  solver = Solver(model, small_data,\n",
    "                  num_epochs=25, batch_size=100,\n",
    "                  update_rule='adam',\n",
    "                  optim_config={\n",
    "                    'learning_rate': 5e-4,\n",
    "                  },\n",
    "                  verbose=True, print_every=100)\n",
    "  solver.train()\n",
    "  solvers[dropout] = solver\n",
    "  print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot train and validation accuracies of the two models\n",
    "\n",
    "train_accs = []\n",
    "val_accs = []\n",
    "for dropout in dropout_choices:\n",
    "  solver = solvers[dropout]\n",
    "  train_accs.append(solver.train_acc_history[-1])\n",
    "  val_accs.append(solver.val_acc_history[-1])\n",
    "\n",
    "plt.subplot(3, 1, 1)\n",
    "for dropout in dropout_choices:\n",
    "  plt.plot(solvers[dropout].train_acc_history, 'o', label='%.2f dropout' % dropout)\n",
    "plt.title('Train accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend(ncol=2, loc='lower right')\n",
    "  \n",
    "plt.subplot(3, 1, 2)\n",
    "for dropout in dropout_choices:\n",
    "  plt.plot(solvers[dropout].val_acc_history, 'o', label='%.2f dropout' % dropout)\n",
    "plt.title('Val accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend(ncol=2, loc='lower right')\n",
    "\n",
    "plt.gcf().set_size_inches(15, 15)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Сверточные нейронные сети (CNN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Реализуйте прямой проход для сверточного слоя - функция conv_forward_naive в scripts/layers.py юПроверьте свою реализацию, запустив код ниже "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing conv_forward_naive\n",
      "difference:  2.2121476417505994e-08\n"
     ]
    }
   ],
   "source": [
    "x_shape = (2, 3, 4, 4)\n",
    "w_shape = (3, 3, 4, 4)\n",
    "x = np.linspace(-0.1, 0.5, num=np.prod(x_shape)).reshape(x_shape)\n",
    "w = np.linspace(-0.2, 0.3, num=np.prod(w_shape)).reshape(w_shape)\n",
    "b = np.linspace(-0.1, 0.2, num=3)\n",
    "\n",
    "conv_param = {'stride': 2, 'pad': 1}\n",
    "out, _ = conv_forward_naive(x, w, b, conv_param)\n",
    "correct_out = np.array([[[[-0.08759809, -0.10987781],\n",
    "                           [-0.18387192, -0.2109216 ]],\n",
    "                          [[ 0.21027089,  0.21661097],\n",
    "                           [ 0.22847626,  0.23004637]],\n",
    "                          [[ 0.50813986,  0.54309974],\n",
    "                           [ 0.64082444,  0.67101435]]],\n",
    "                         [[[-0.98053589, -1.03143541],\n",
    "                           [-1.19128892, -1.24695841]],\n",
    "                          [[ 0.69108355,  0.66880383],\n",
    "                           [ 0.59480972,  0.56776003]],\n",
    "                          [[ 2.36270298,  2.36904306],\n",
    "                           [ 2.38090835,  2.38247847]]]])\n",
    "\n",
    "# Compare your output to ours; difference should be around e-8\n",
    "print('Testing conv_forward_naive')\n",
    "print('difference: ', rel_error(out, correct_out))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Реализуйте обратный проход - функция conv_backward_naive в scripts/layers.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing conv_backward_naive function\n",
      "dx error:  1.159803161159293e-08\n",
      "dw error:  2.247109434939654e-10\n",
      "db error:  3.37264006649648e-11\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(231)\n",
    "x = np.random.randn(4, 3, 5, 5)\n",
    "w = np.random.randn(2, 3, 3, 3)\n",
    "b = np.random.randn(2,)\n",
    "dout = np.random.randn(4, 2, 5, 5)\n",
    "conv_param = {'stride': 1, 'pad': 1}\n",
    "\n",
    "dx_num = eval_numerical_gradient_array(lambda x: conv_forward_naive(x, w, b, conv_param)[0], x, dout)\n",
    "dw_num = eval_numerical_gradient_array(lambda w: conv_forward_naive(x, w, b, conv_param)[0], w, dout)\n",
    "db_num = eval_numerical_gradient_array(lambda b: conv_forward_naive(x, w, b, conv_param)[0], b, dout)\n",
    "\n",
    "out, cache = conv_forward_naive(x, w, b, conv_param)\n",
    "dx, dw, db = conv_backward_naive(dout, cache)\n",
    "\n",
    "# Your errors should be around e-8 or less.\n",
    "print('Testing conv_backward_naive function')\n",
    "print('dx error: ', rel_error(dx, dx_num))\n",
    "print('dw error: ', rel_error(dw, dw_num))\n",
    "print('db error: ', rel_error(db, db_num))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Реализуйте прямой проход для max-pooling слоя -функция  max_pool_forward_naive в scripts/layers.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing max_pool_forward_naive function:\n",
      "difference:  4.1666665157267834e-08\n"
     ]
    }
   ],
   "source": [
    "x_shape = (2, 3, 4, 4)\n",
    "x = np.linspace(-0.3, 0.4, num=np.prod(x_shape)).reshape(x_shape)\n",
    "pool_param = {'pool_width': 2, 'pool_height': 2, 'stride': 2}\n",
    "\n",
    "out, _ = max_pool_forward_naive(x, pool_param)\n",
    "\n",
    "correct_out = np.array([[[[-0.26315789, -0.24842105],\n",
    "                          [-0.20421053, -0.18947368]],\n",
    "                         [[-0.14526316, -0.13052632],\n",
    "                          [-0.08631579, -0.07157895]],\n",
    "                         [[-0.02736842, -0.01263158],\n",
    "                          [ 0.03157895,  0.04631579]]],\n",
    "                        [[[ 0.09052632,  0.10526316],\n",
    "                          [ 0.14947368,  0.16421053]],\n",
    "                         [[ 0.20842105,  0.22315789],\n",
    "                          [ 0.26736842,  0.28210526]],\n",
    "                         [[ 0.32631579,  0.34105263],\n",
    "                          [ 0.38526316,  0.4       ]]]])\n",
    "\n",
    "# Compare your output with ours. Difference should be on the order of e-8.\n",
    "print('Testing max_pool_forward_naive function:')\n",
    "print('difference: ', rel_error(out, correct_out))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Реализуйте обратный проход для max-pooling слоя в max_pool_backward_naive . "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing max_pool_backward_naive function:\n",
      "dx error:  3.27562514223145e-12\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(231)\n",
    "x = np.random.randn(3, 2, 8, 8)\n",
    "dout = np.random.randn(3, 2, 4, 4)\n",
    "pool_param = {'pool_height': 2, 'pool_width': 2, 'stride': 2}\n",
    "\n",
    "dx_num = eval_numerical_gradient_array(lambda x: max_pool_forward_naive(x, pool_param)[0], x, dout)\n",
    "\n",
    "out, cache = max_pool_forward_naive(x, pool_param)\n",
    "dx = max_pool_backward_naive(dout, cache)\n",
    "\n",
    "# Your error should be on the order of e-12\n",
    "print('Testing max_pool_backward_naive function:')\n",
    "print('dx error: ', rel_error(dx, dx_num))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В скрипте scripts/fast_layers.py представлены быстрые реализации слоев свертки и пуллинга, написанных с использованием  Cython. \n",
    "\n",
    "Для компиляции выполните следующую команду в директории scripts\n",
    "\n",
    "```bash\n",
    "python setup.py build_ext --inplace\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сравните ваши реализации слоев свертки и пуллинга с быстрыми реализациями."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing conv_forward_fast:\n",
      "Naive: 0.070194s\n",
      "Fast: 0.149217s\n",
      "Speedup: 0.470417x\n",
      "Difference:  4.926407851494105e-11\n",
      "\n",
      "Testing conv_backward_fast:\n",
      "Naive: 0.295558s\n",
      "Fast: 0.008726s\n",
      "Speedup: 33.870519x\n",
      "dx difference:  1.006330206620509e-11\n",
      "dw difference:  2.1696484210947452e-13\n",
      "db difference:  0.0\n"
     ]
    }
   ],
   "source": [
    "# Rel errors should be around e-9 or less\n",
    "from scripts.fast_layers import conv_forward_fast, conv_backward_fast\n",
    "from time import time\n",
    "np.random.seed(231)\n",
    "x = np.random.randn(100, 3, 31, 31)\n",
    "w = np.random.randn(25, 3, 3, 3)\n",
    "b = np.random.randn(25,)\n",
    "dout = np.random.randn(100, 25, 16, 16)\n",
    "conv_param = {'stride': 2, 'pad': 1}\n",
    "\n",
    "t0 = time()\n",
    "out_naive, cache_naive = conv_forward_naive(x, w, b, conv_param)\n",
    "t1 = time()\n",
    "out_fast, cache_fast = conv_forward_fast(x, w, b, conv_param)\n",
    "t2 = time()\n",
    "\n",
    "print('Testing conv_forward_fast:')\n",
    "print('Naive: %fs' % (t1 - t0))\n",
    "print('Fast: %fs' % (t2 - t1))\n",
    "print('Speedup: %fx' % ((t1 - t0) / (t2 - t1)))\n",
    "print('Difference: ', rel_error(out_naive, out_fast))\n",
    "\n",
    "t0 = time()\n",
    "dx_naive, dw_naive, db_naive = conv_backward_naive(dout, cache_naive)\n",
    "t1 = time()\n",
    "dx_fast, dw_fast, db_fast = conv_backward_fast(dout, cache_fast)\n",
    "t2 = time()\n",
    "\n",
    "print('\\nTesting conv_backward_fast:')\n",
    "print('Naive: %fs' % (t1 - t0))\n",
    "print('Fast: %fs' % (t2 - t1))\n",
    "print('Speedup: %fx' % ((t1 - t0) / (t2 - t1)))\n",
    "print('dx difference: ', rel_error(dx_naive, dx_fast))\n",
    "print('dw difference: ', rel_error(dw_naive, dw_fast))\n",
    "print('db difference: ', rel_error(db_naive, db_fast))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing pool_forward_fast:\n",
      "Naive: 0.006979s\n",
      "fast: 0.005004s\n",
      "speedup: 1.394474x\n",
      "difference:  0.0\n",
      "\n",
      "Testing pool_backward_fast:\n",
      "Naive: 0.016073s\n",
      "fast: 0.008996s\n",
      "speedup: 1.786680x\n",
      "dx difference:  0.0\n"
     ]
    }
   ],
   "source": [
    "# Relative errors should be close to 0.0\n",
    "from scripts.fast_layers import max_pool_forward_fast, max_pool_backward_fast\n",
    "np.random.seed(231)\n",
    "x = np.random.randn(100, 3, 32, 32)\n",
    "dout = np.random.randn(100, 3, 16, 16)\n",
    "pool_param = {'pool_height': 2, 'pool_width': 2, 'stride': 2}\n",
    "\n",
    "t0 = time()\n",
    "out_naive, cache_naive = max_pool_forward_naive(x, pool_param)\n",
    "t1 = time()\n",
    "out_fast, cache_fast = max_pool_forward_fast(x, pool_param)\n",
    "t2 = time()\n",
    "\n",
    "print('Testing pool_forward_fast:')\n",
    "print('Naive: %fs' % (t1 - t0))\n",
    "print('fast: %fs' % (t2 - t1))\n",
    "print('speedup: %fx' % ((t1 - t0) / (t2 - t1)))\n",
    "print('difference: ', rel_error(out_naive, out_fast))\n",
    "\n",
    "t0 = time()\n",
    "dx_naive = max_pool_backward_naive(dout, cache_naive)\n",
    "t1 = time()\n",
    "dx_fast = max_pool_backward_fast(dout, cache_fast)\n",
    "t2 = time()\n",
    "\n",
    "print('\\nTesting pool_backward_fast:')\n",
    "print('Naive: %fs' % (t1 - t0))\n",
    "print('fast: %fs' % (t2 - t1))\n",
    "print('speedup: %fx' % ((t1 - t0) / (t2 - t1)))\n",
    "print('dx difference: ', rel_error(dx_naive, dx_fast))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В layer_utils.py вы можете найти  часто используемые комбинации слоев, используемых в сверточных сетях. Ознакомьтесь с ними и запустите код ниже для проверки их работы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing conv_relu_pool\n",
      "dx error:  9.591132621921372e-09\n",
      "dw error:  5.802428657473038e-09\n",
      "db error:  3.57960501324485e-10\n"
     ]
    }
   ],
   "source": [
    "from scripts.layer_utils import conv_relu_pool_forward, conv_relu_pool_backward\n",
    "np.random.seed(231)\n",
    "x = np.random.randn(2, 3, 16, 16)\n",
    "w = np.random.randn(3, 3, 3, 3)\n",
    "b = np.random.randn(3,)\n",
    "dout = np.random.randn(2, 3, 8, 8)\n",
    "conv_param = {'stride': 1, 'pad': 1}\n",
    "pool_param = {'pool_height': 2, 'pool_width': 2, 'stride': 2}\n",
    "\n",
    "out, cache = conv_relu_pool_forward(x, w, b, conv_param, pool_param)\n",
    "dx, dw, db = conv_relu_pool_backward(dout, cache)\n",
    "\n",
    "dx_num = eval_numerical_gradient_array(lambda x: conv_relu_pool_forward(x, w, b, conv_param, pool_param)[0], x, dout)\n",
    "dw_num = eval_numerical_gradient_array(lambda w: conv_relu_pool_forward(x, w, b, conv_param, pool_param)[0], w, dout)\n",
    "db_num = eval_numerical_gradient_array(lambda b: conv_relu_pool_forward(x, w, b, conv_param, pool_param)[0], b, dout)\n",
    "\n",
    "# Relative errors should be around e-8 or less\n",
    "print('Testing conv_relu_pool')\n",
    "print('dx error: ', rel_error(dx_num, dx))\n",
    "print('dw error: ', rel_error(dw_num, dw))\n",
    "print('db error: ', rel_error(db_num, db))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing conv_relu:\n",
      "dx error:  1.5218619980349303e-09\n",
      "dw error:  3.371588501430134e-10\n",
      "db error:  4.8422803898140394e-11\n"
     ]
    }
   ],
   "source": [
    "from scripts.layer_utils import conv_relu_forward, conv_relu_backward\n",
    "np.random.seed(231)\n",
    "x = np.random.randn(2, 3, 8, 8)\n",
    "w = np.random.randn(3, 3, 3, 3)\n",
    "b = np.random.randn(3,)\n",
    "dout = np.random.randn(2, 3, 8, 8)\n",
    "conv_param = {'stride': 1, 'pad': 1}\n",
    "\n",
    "out, cache = conv_relu_forward(x, w, b, conv_param)\n",
    "dx, dw, db = conv_relu_backward(dout, cache)\n",
    "\n",
    "dx_num = eval_numerical_gradient_array(lambda x: conv_relu_forward(x, w, b, conv_param)[0], x, dout)\n",
    "dw_num = eval_numerical_gradient_array(lambda w: conv_relu_forward(x, w, b, conv_param)[0], w, dout)\n",
    "db_num = eval_numerical_gradient_array(lambda b: conv_relu_forward(x, w, b, conv_param)[0], b, dout)\n",
    "\n",
    "# Relative errors should be around e-8 or less\n",
    "print('Testing conv_relu:')\n",
    "print('dx error: ', rel_error(dx_num, dx))\n",
    "print('dw error: ', rel_error(dw_num, dw))\n",
    "print('db error: ', rel_error(db_num, db))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Напишите реализацию класса ThreeLayerConvNet в scripts/classifiers/cnn.py . Вы можете использовать готовые реализации слоев и их комбинаций."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Проверьте вашу реализацию. Ожидается, что значение функции потерь softmax будет порядка `log(C)` для `C` классов для случая без регуляризации. В случае регуляризации значение функции потерь должно немного возрасти. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial loss (no regularization):  2.3025851440429688\n",
      "Initial loss (with regularization):  2.315956645917613\n"
     ]
    }
   ],
   "source": [
    "model = ThreeLayerConvNet(input_dim=(1, 8, 8))\n",
    "\n",
    "N = 50\n",
    "X = np.random.randn(N, 1, 8, 8)\n",
    "y = np.random.randint(10, size=N)\n",
    "\n",
    "loss, grads = model.loss(X, y)\n",
    "print('Initial loss (no regularization): ', loss)\n",
    "\n",
    "model.reg = 0.5\n",
    "loss, grads = model.loss(X, y)\n",
    "print('Initial loss (with regularization): ', loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Проверьте реализацию обратного прохода"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W1 max relative error: 8.230171e-05\n",
      "W2 max relative error: 8.001594e-03\n",
      "W3 max relative error: 1.426327e-04\n",
      "b1 max relative error: 1.292505e-05\n",
      "b2 max relative error: 6.629029e-07\n",
      "b3 max relative error: 1.306698e-09\n"
     ]
    }
   ],
   "source": [
    "num_inputs = 2\n",
    "input_dim = (1, 8, 8)\n",
    "reg = 0.0\n",
    "num_classes = 10\n",
    "np.random.seed(231)\n",
    "X = np.random.randn(num_inputs, *input_dim)\n",
    "y = np.random.randint(num_classes, size=num_inputs)\n",
    "\n",
    "model = ThreeLayerConvNet(num_filters=3, filter_size=3,\n",
    "                          input_dim=input_dim, hidden_dim=7,\n",
    "                          dtype=np.float64)\n",
    "loss, grads = model.loss(X, y)\n",
    "# Errors should be small, but correct implementations may have\n",
    "# relative errors up to the order of e-2\n",
    "for param_name in sorted(grads):\n",
    "    f = lambda _: model.loss(X, y)[0]\n",
    "    param_grad_num = eval_numerical_gradient(f, model.params[param_name], verbose=False, h=1e-6)\n",
    "    e = rel_error(param_grad_num, grads[param_name])\n",
    "    print('%s max relative error: %e' % (param_name, rel_error(param_grad_num, grads[param_name])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Попробуйте добиться эффекта переобучения. Обучите модель на небольшом наборе данных.Сравните значения accuracy на обучающих данных и на валидационных. Визуализируйте графики обучения "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Iteration 1 / 40) loss: 2.302363\n",
      "(Epoch 0 / 20) train acc: 0.140000; val_acc: 0.138889\n",
      "(Iteration 2 / 40) loss: 2.288100\n",
      "(Epoch 1 / 20) train acc: 0.140000; val_acc: 0.131944\n",
      "(Iteration 3 / 40) loss: 2.295211\n",
      "(Iteration 4 / 40) loss: 2.263874\n",
      "(Epoch 2 / 20) train acc: 0.140000; val_acc: 0.131944\n",
      "(Iteration 5 / 40) loss: 2.258504\n",
      "(Iteration 6 / 40) loss: 2.211802\n",
      "(Epoch 3 / 20) train acc: 0.260000; val_acc: 0.250000\n",
      "(Iteration 7 / 40) loss: 2.217068\n",
      "(Iteration 8 / 40) loss: 2.213770\n",
      "(Epoch 4 / 20) train acc: 0.270000; val_acc: 0.256944\n",
      "(Iteration 9 / 40) loss: 2.188468\n",
      "(Iteration 10 / 40) loss: 2.221439\n",
      "(Epoch 5 / 20) train acc: 0.270000; val_acc: 0.256944\n",
      "(Iteration 11 / 40) loss: 2.115352\n",
      "(Iteration 12 / 40) loss: 2.076630\n",
      "(Epoch 6 / 20) train acc: 0.280000; val_acc: 0.270833\n",
      "(Iteration 13 / 40) loss: 2.182471\n",
      "(Iteration 14 / 40) loss: 2.167571\n",
      "(Epoch 7 / 20) train acc: 0.340000; val_acc: 0.277778\n",
      "(Iteration 15 / 40) loss: 2.115407\n",
      "(Iteration 16 / 40) loss: 2.028273\n",
      "(Epoch 8 / 20) train acc: 0.550000; val_acc: 0.423611\n",
      "(Iteration 17 / 40) loss: 2.045029\n",
      "(Iteration 18 / 40) loss: 2.021576\n",
      "(Epoch 9 / 20) train acc: 0.540000; val_acc: 0.395833\n",
      "(Iteration 19 / 40) loss: 1.943903\n",
      "(Iteration 20 / 40) loss: 1.810536\n",
      "(Epoch 10 / 20) train acc: 0.620000; val_acc: 0.493056\n",
      "(Iteration 21 / 40) loss: 1.850967\n",
      "(Iteration 22 / 40) loss: 1.708089\n",
      "(Epoch 11 / 20) train acc: 0.580000; val_acc: 0.493056\n",
      "(Iteration 23 / 40) loss: 1.689670\n",
      "(Iteration 24 / 40) loss: 1.599429\n",
      "(Epoch 12 / 20) train acc: 0.530000; val_acc: 0.444444\n",
      "(Iteration 25 / 40) loss: 1.534577\n",
      "(Iteration 26 / 40) loss: 1.564545\n",
      "(Epoch 13 / 20) train acc: 0.650000; val_acc: 0.548611\n",
      "(Iteration 27 / 40) loss: 1.433715\n",
      "(Iteration 28 / 40) loss: 1.334102\n",
      "(Epoch 14 / 20) train acc: 0.720000; val_acc: 0.597222\n",
      "(Iteration 29 / 40) loss: 1.077853\n",
      "(Iteration 30 / 40) loss: 1.134121\n",
      "(Epoch 15 / 20) train acc: 0.740000; val_acc: 0.597222\n",
      "(Iteration 31 / 40) loss: 1.245831\n",
      "(Iteration 32 / 40) loss: 1.136511\n",
      "(Epoch 16 / 20) train acc: 0.810000; val_acc: 0.618056\n",
      "(Iteration 33 / 40) loss: 0.849144\n",
      "(Iteration 34 / 40) loss: 0.978313\n",
      "(Epoch 17 / 20) train acc: 0.780000; val_acc: 0.597222\n",
      "(Iteration 35 / 40) loss: 0.753107\n",
      "(Iteration 36 / 40) loss: 0.804720\n",
      "(Epoch 18 / 20) train acc: 0.770000; val_acc: 0.638889\n",
      "(Iteration 37 / 40) loss: 0.774503\n",
      "(Iteration 38 / 40) loss: 0.791722\n",
      "(Epoch 19 / 20) train acc: 0.800000; val_acc: 0.673611\n",
      "(Iteration 39 / 40) loss: 0.616393\n",
      "(Iteration 40 / 40) loss: 0.819838\n",
      "(Epoch 20 / 20) train acc: 0.910000; val_acc: 0.743056\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(231)\n",
    "\n",
    "num_train = 100\n",
    "small_data = {\n",
    "  'X_train': data['X_train'][:num_train],\n",
    "  'y_train': data['y_train'][:num_train],\n",
    "  'X_val': data['X_val'],\n",
    "  'y_val': data['y_val'],\n",
    "}\n",
    "\n",
    "model = ThreeLayerConvNet(weight_scale=1e-2, input_dim=(1, 8, 8))\n",
    "\n",
    "solver = Solver(model, small_data,\n",
    "                num_epochs=20, batch_size=50,\n",
    "                update_rule='adam',\n",
    "                optim_config={\n",
    "                  'learning_rate': 1e-3,\n",
    "                },\n",
    "                verbose=True, print_every=1)\n",
    "solver.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Small data training accuracy: 0.91\n"
     ]
    }
   ],
   "source": [
    "# Print final training accuracy\n",
    "print(\n",
    "    \"Small data training accuracy:\",\n",
    "    solver.check_accuracy(small_data['X_train'], small_data['y_train'])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Small data validation accuracy: 0.7430555555555556\n"
     ]
    }
   ],
   "source": [
    "# Print final validation accuracy\n",
    "print(\n",
    "    \"Small data validation accuracy:\",\n",
    "    solver.check_accuracy(small_data['X_val'], small_data['y_val'])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1000x800 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.subplot(2, 1, 1)\n",
    "plt.plot(solver.loss_history, 'o')\n",
    "plt.xlabel('iteration')\n",
    "plt.ylabel('loss')\n",
    "\n",
    "plt.subplot(2, 1, 2)\n",
    "plt.plot(solver.train_acc_history, '-o')\n",
    "plt.plot(solver.val_acc_history, '-o')\n",
    "plt.legend(['train', 'val'], loc='upper left')\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('accuracy')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обучите сеть на полном наборе данных. Выведите accuracy на обучающей и валидационной выборках"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Iteration 1 / 125) loss: 2.302715\n",
      "(Epoch 0 / 5) train acc: 0.190000; val_acc: 0.173611\n",
      "(Iteration 21 / 125) loss: 1.908050\n",
      "(Epoch 1 / 5) train acc: 0.542000; val_acc: 0.576389\n",
      "(Iteration 41 / 125) loss: 0.726518\n",
      "(Epoch 2 / 5) train acc: 0.784000; val_acc: 0.791667\n",
      "(Iteration 61 / 125) loss: 0.331574\n",
      "(Epoch 3 / 5) train acc: 0.897000; val_acc: 0.861111\n",
      "(Iteration 81 / 125) loss: 0.255312\n",
      "(Epoch 4 / 5) train acc: 0.951000; val_acc: 0.909722\n",
      "(Iteration 101 / 125) loss: 0.273811\n",
      "(Iteration 121 / 125) loss: 0.264112\n",
      "(Epoch 5 / 5) train acc: 0.945000; val_acc: 0.895833\n"
     ]
    }
   ],
   "source": [
    "model = ThreeLayerConvNet(weight_scale=0.001, hidden_dim=500, reg=0.001, input_dim=(1, 8, 8))\n",
    "\n",
    "solver = Solver(model, data,\n",
    "                num_epochs=5, batch_size=50,\n",
    "                update_rule='adam',\n",
    "                optim_config={\n",
    "                  'learning_rate': 1e-3,\n",
    "                },\n",
    "                verbose=True, print_every=20)\n",
    "solver.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full data training accuracy: 0.94\n"
     ]
    }
   ],
   "source": [
    "# Print final training accuracy\n",
    "print(\n",
    "    \"Full data training accuracy:\",\n",
    "    solver.check_accuracy(small_data['X_train'], small_data['y_train'])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full data validation accuracy: 0.9097222222222222\n"
     ]
    }
   ],
   "source": [
    "# Print final validation accuracy\n",
    "print(\n",
    "    \"Full data validation accuracy:\",\n",
    "    solver.check_accuracy(data['X_val'], data['y_val'])\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Визуализируйте фильтры на первом слое обученной сети"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 500x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from scripts.vis_utils import visualize_grid\n",
    "\n",
    "grid = visualize_grid(model.params['W1'].transpose(0, 2, 3, 1))\n",
    "plt.imshow(grid.astype('uint8'))\n",
    "plt.axis('off')\n",
    "plt.gcf().set_size_inches(5, 5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
